{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing PySpark Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "print(\"Demo Notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to EMR Cluster\n",
    "\n",
    "In the cell below, the code block is autogenerated. You can generate this code by clicking on the \"Cluster\" link on the top of the notebook and select the EMR cluster. The \"j-xxxxxxxxxxxx\" is the cluster id of the cluster selected. \n",
    "\n",
    "For the example in this [blog](https://aws.amazon.com/blogs/machine-learning/part-1-create-and-manage-amazon-emr-clusters-from-sagemaker-studio-to-run-interactive-spark-and-ml-workloads/), we used a no-auth cluster for simplicity, but this works equally well for Kerberos, LDAP and HTTP auth mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "instance_type": "ml.t3.medium",
    "kernelspec": {
     "display_name": "SparkMagic PySpark",
     "language": "python",
     "name": "pysparkkernel"
    },
    "language_info": {
     "codemirror_mode": {
      "name": "python",
      "version": 3
     },
     "file_extension": ".py",
     "mimetype": "text/x-python",
     "name": "pyspark",
     "pygments_lexer": "python3"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext sagemaker_studio_analytics_extension.magics\n",
    "# %sm_analytics emr connect --verify-certificate False --cluster-id <> --auth-type None --language python  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we will use the HiveContext to query Hive and look at the databases and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = sqlContext.sql(\"show databases\")\n",
    "dbs.show()\n",
    "\n",
    "tables = sqlContext.sql(\"show tables\")\n",
    "tables.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = sqlContext.sql(\"select * from movie_reviews\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "print((movie_reviews.count(), len(movie_reviews.columns)))\n",
    "# count of both positive and negative sentiments\n",
    "movie_reviews.groupBy('sentiment').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_reviews = movie_reviews.filter(movie_reviews.sentiment == 'positive').collect()\n",
    "neg_reviews = movie_reviews.filter(movie_reviews.sentiment == 'negative').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_counts(positive,negative):\n",
    "    plt.rcParams['figure.figsize']=(6,6)\n",
    "    plt.bar(0,positive,width=0.6,label='Positive Reviews',color='Green')\n",
    "    plt.bar(2,negative,width=0.6,label='Negative Reviews',color='Red')\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Type of Review')\n",
    "    plt.tick_params(\n",
    "        axis='x',          \n",
    "        which='both',      \n",
    "        bottom=False,      \n",
    "        top=False,         \n",
    "        labelbottom=False) \n",
    "    plt.show()\n",
    "    \n",
    "plot_counts(len(pos_reviews),len(neg_reviews))\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Let's inspect length of reviews using the pyspark.sql.functions module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length\n",
    "reviewlengthDF = movie_reviews.select(length('review').alias('Length of Review')) \n",
    "reviewlengthDF.show() "
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "SparkMagic PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
