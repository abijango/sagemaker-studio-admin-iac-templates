{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b43513c-5b7d-43fa-a52b-58cc0269b17d",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd38eb1-5b39-4007-a64b-1a78c50726f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9b710-34b7-4223-a42c-f39fabc8cea0",
   "metadata": {},
   "source": [
    "# Import SageMaker Defaults Configurations\n",
    "\n",
    "The Amazon SageMaker Python SDK supports setting of default values for AWS infrastructure primitive types, such as instance types, Amazon S3 folder locations, and IAM roles. You can override the default locations of these files by setting the `SAGEMAKER_USER_CONFIG_OVERRIDE` environment variables for the user-defined configuration file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532bf10-e09d-4db9-89bc-075f43127781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use the current working directory as the location for SageMaker Python SDK config file\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97fa9c2-5286-4352-91f6-ef4e8cb9336f",
   "metadata": {},
   "source": [
    "# Download dataset\n",
    "\n",
    "Download the dataset from the UCI website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a879f4d-dbc6-4059-95c9-c663d679dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "\n",
    "input_data_dir = 'data/'\n",
    "if not os.path.exists(input_data_dir):\n",
    "    os.makedirs(input_data_dir)\n",
    "input_data_path = os.path.join(input_data_dir, 'predictive_maintenance_raw_data_header.csv')\n",
    "dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv\"\n",
    "urllib.request.urlretrieve(dataset_url, input_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a696576-4402-4eb7-a0ba-fce791452037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(input_data_path)\n",
    "\n",
    "print('The shape of the dataset is:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e50a99b-2f17-4449-9719-f30d89687cfb",
   "metadata": {},
   "source": [
    "# Test case 1: Run a SageMaker Job without Networking configurations\n",
    "\n",
    "## Expected result: Job should fail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfaec1d-82d4-4261-818d-798f70e2cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sagemaker.remote_function import remote\n",
    "\n",
    "@remote(job_name_prefix=\"amzn-sm-btd-preprocess\")\n",
    "def preprocess(df):\n",
    "    columns = ['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Machine failure']\n",
    "    cat_columns = ['Type']\n",
    "    num_columns = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
    "    target_column = 'Machine failure'\n",
    "\n",
    "    df = df[columns]\n",
    "\n",
    "    training_ratio = 0.8\n",
    "    validation_ratio = 0.1\n",
    "    test_ratio = 0.1\n",
    "\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "\n",
    "    print(f'Splitting data training ({training_ratio}), validation ({validation_ratio}), and test ({test_ratio}) sets ')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_ratio/(validation_ratio+training_ratio), random_state=2, stratify=y_train)\n",
    "\n",
    "    # Apply transformations\n",
    "    transformer = ColumnTransformer(transformers=[('numeric', StandardScaler(), num_columns),\n",
    "                                                  ('categorical', OneHotEncoder(), cat_columns)],\n",
    "                                    remainder='passthrough')\n",
    "    featurizer_model = transformer.fit(X_train)\n",
    "    X_train = featurizer_model.transform(X_train)\n",
    "    X_val = featurizer_model.transform(X_val)\n",
    "\n",
    "    print(f'Shape of train features after preprocessing: {X_train.shape}')\n",
    "    print(f'Shape of validation features after preprocessing: {X_val.shape}')\n",
    "    print(f'Shape of test features after preprocessing: {X_test.shape}')\n",
    "    \n",
    "    y_train = y_train.values.reshape(-1)\n",
    "    y_val = y_val.values.reshape(-1)\n",
    "    \n",
    "    print(f'Shape of train labels after preprocessing: {y_train.shape}')\n",
    "    print(f'Shape of validation labels after preprocessing: {y_val.shape}')\n",
    "    print(f'Shape of test labels after preprocessing: {y_test.shape}')\n",
    "\n",
    "    model_file_path=\"/opt/ml/model/sklearn_model.joblib\"\n",
    "    os.makedirs(os.path.dirname(model_file_path), exist_ok=True)\n",
    "    joblib.dump(featurizer_model, model_file_path)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, featurizer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cebde5c-fffa-41af-a46c-e83263f339a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, featurizer_model = preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35d519-130f-45c9-847f-93167bfe9ba6",
   "metadata": {},
   "source": [
    "# Test case 2: Run a SageMaker Job with Networking configurations\n",
    "\n",
    "## Expected result: The job should be successfully executed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d02b8-652e-410c-a525-f1e5963a5893",
   "metadata": {},
   "source": [
    "## Subnet and security group definition\n",
    "\n",
    "#### ! Important: Populate subnets and security_group_ids by using the exported values from the CloudFormation template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26abc68f-ddd7-4392-8127-94a97e271e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnets = []\n",
    "security_group_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7f1e7-5073-4979-92b3-ec81e3bf2cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sagemaker.remote_function import remote\n",
    "\n",
    "@remote(job_name_prefix=\"amzn-sm-btd-preprocess\", subnets=subnets, security_group_ids=security_group_ids)\n",
    "def preprocess(df):\n",
    "    columns = ['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Machine failure']\n",
    "    cat_columns = ['Type']\n",
    "    num_columns = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
    "    target_column = 'Machine failure'\n",
    "\n",
    "    df = df[columns]\n",
    "\n",
    "    training_ratio = 0.8\n",
    "    validation_ratio = 0.1\n",
    "    test_ratio = 0.1\n",
    "\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "\n",
    "    print(f'Splitting data training ({training_ratio}), validation ({validation_ratio}), and test ({test_ratio}) sets ')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_ratio/(validation_ratio+training_ratio), random_state=2, stratify=y_train)\n",
    "\n",
    "    # Apply transformations\n",
    "    transformer = ColumnTransformer(transformers=[('numeric', StandardScaler(), num_columns),\n",
    "                                                  ('categorical', OneHotEncoder(), cat_columns)],\n",
    "                                    remainder='passthrough')\n",
    "    featurizer_model = transformer.fit(X_train)\n",
    "    X_train = featurizer_model.transform(X_train)\n",
    "    X_val = featurizer_model.transform(X_val)\n",
    "\n",
    "    print(f'Shape of train features after preprocessing: {X_train.shape}')\n",
    "    print(f'Shape of validation features after preprocessing: {X_val.shape}')\n",
    "    print(f'Shape of test features after preprocessing: {X_test.shape}')\n",
    "    \n",
    "    y_train = y_train.values.reshape(-1)\n",
    "    y_val = y_val.values.reshape(-1)\n",
    "    \n",
    "    print(f'Shape of train labels after preprocessing: {y_train.shape}')\n",
    "    print(f'Shape of validation labels after preprocessing: {y_val.shape}')\n",
    "    print(f'Shape of test labels after preprocessing: {y_test.shape}')\n",
    "\n",
    "    model_file_path=\"/opt/ml/model/sklearn_model.joblib\"\n",
    "    os.makedirs(os.path.dirname(model_file_path), exist_ok=True)\n",
    "    joblib.dump(featurizer_model, model_file_path)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, featurizer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73afdca9-1f4a-462c-bb65-47baa141d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, featurizer_model = preprocess(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
