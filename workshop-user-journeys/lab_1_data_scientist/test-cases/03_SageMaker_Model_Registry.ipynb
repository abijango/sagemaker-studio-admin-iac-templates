{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b43513c-5b7d-43fa-a52b-58cc0269b17d",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd38eb1-5b39-4007-a64b-1a78c50726f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9b710-34b7-4223-a42c-f39fabc8cea0",
   "metadata": {},
   "source": [
    "# Import SageMaker Defaults Configurations\n",
    "\n",
    "The Amazon SageMaker Python SDK supports setting of default values for AWS infrastructure primitive types, such as instance types, Amazon S3 folder locations, and IAM roles. You can override the default locations of these files by setting the `SAGEMAKER_USER_CONFIG_OVERRIDE` environment variables for the user-defined configuration file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532bf10-e09d-4db9-89bc-075f43127781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use the current working directory as the location for SageMaker Python SDK config file\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97fa9c2-5286-4352-91f6-ef4e8cb9336f",
   "metadata": {},
   "source": [
    "# Download dataset\n",
    "\n",
    "Download the dataset from the UCI website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a879f4d-dbc6-4059-95c9-c663d679dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "\n",
    "input_data_dir = 'data/'\n",
    "if not os.path.exists(input_data_dir):\n",
    "    os.makedirs(input_data_dir)\n",
    "input_data_path = os.path.join(input_data_dir, 'predictive_maintenance_raw_data_header.csv')\n",
    "dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv\"\n",
    "urllib.request.urlretrieve(dataset_url, input_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a696576-4402-4eb7-a0ba-fce791452037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(input_data_path)\n",
    "\n",
    "print('The shape of the dataset is:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c73b813-95f4-4d4c-a701-2eb23523d901",
   "metadata": {},
   "source": [
    "# Test case 1: Register model in model registry\n",
    "\n",
    "## Expected result: A new model version should be registered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686bcda-a6a2-46ef-9496-2e905d99b6d4",
   "metadata": {},
   "source": [
    "#### ! Important: Populate subnets and security_group_ids by using the exported values from the CloudFormation template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb140719-c21d-42f4-a7d0-9a2cb4501593",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnets = []\n",
    "security_group_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40532a1f-68ee-4d0e-a46e-919249aebc6b",
   "metadata": {},
   "source": [
    "Run data processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24cd97e-6cbb-4bd3-8cdc-84cc2e50e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sagemaker.remote_function import remote\n",
    "\n",
    "@remote(job_name_prefix=\"amzn-sm-btd-preprocess\", subnets=subnets, security_group_ids=security_group_ids)\n",
    "def preprocess(df):\n",
    "    columns = ['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Machine failure']\n",
    "    cat_columns = ['Type']\n",
    "    num_columns = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
    "    target_column = 'Machine failure'\n",
    "\n",
    "    df = df[columns]\n",
    "\n",
    "    training_ratio = 0.8\n",
    "    validation_ratio = 0.1\n",
    "    test_ratio = 0.1\n",
    "\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "\n",
    "    print(f'Splitting data training ({training_ratio}), validation ({validation_ratio}), and test ({test_ratio}) sets ')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_ratio/(validation_ratio+training_ratio), random_state=2, stratify=y_train)\n",
    "\n",
    "    # Apply transformations\n",
    "    transformer = ColumnTransformer(transformers=[('numeric', StandardScaler(), num_columns),\n",
    "                                                  ('categorical', OneHotEncoder(), cat_columns)],\n",
    "                                    remainder='passthrough')\n",
    "    featurizer_model = transformer.fit(X_train)\n",
    "    X_train = featurizer_model.transform(X_train)\n",
    "    X_val = featurizer_model.transform(X_val)\n",
    "\n",
    "    print(f'Shape of train features after preprocessing: {X_train.shape}')\n",
    "    print(f'Shape of validation features after preprocessing: {X_val.shape}')\n",
    "    print(f'Shape of test features after preprocessing: {X_test.shape}')\n",
    "    \n",
    "    y_train = y_train.values.reshape(-1)\n",
    "    y_val = y_val.values.reshape(-1)\n",
    "    \n",
    "    print(f'Shape of train labels after preprocessing: {y_train.shape}')\n",
    "    print(f'Shape of validation labels after preprocessing: {y_val.shape}')\n",
    "    print(f'Shape of test labels after preprocessing: {y_test.shape}')\n",
    "\n",
    "    model_file_path=\"/opt/ml/model/sklearn_model.joblib\"\n",
    "    os.makedirs(os.path.dirname(model_file_path), exist_ok=True)\n",
    "    joblib.dump(featurizer_model, model_file_path)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, featurizer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dcc456-4258-44bb-ad10-1d0fa7c82e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, featurizer_model = preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ee840-97c1-44f5-bb86-ea506ebf0eef",
   "metadata": {},
   "source": [
    "Run training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c840c814-69e9-40ed-93b7-c3c44c33bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xgboost\n",
    "import numpy as np\n",
    "\n",
    "from sagemaker.remote_function import remote\n",
    "\n",
    "@remote(job_name_prefix=\"amzn-sm-btd-train\", subnets=subnets, security_group_ids=security_group_ids)\n",
    "def train(X_train, y_train, X_val, y_val,\n",
    "          eta=0.1, \n",
    "          max_depth=2, \n",
    "          gamma=0.0,\n",
    "          min_child_weight=1,\n",
    "          verbosity=0,\n",
    "          objective='binary:logistic',\n",
    "          eval_metric='auc',\n",
    "          num_boost_round=5):\n",
    "\n",
    "    print('Train features shape: {}'.format(X_train.shape))\n",
    "    print('Train labels shape: {}'.format(y_train.shape))\n",
    "    print('Validation features shape: {}'.format(X_val.shape))\n",
    "    print('Validation labels shape: {}'.format(y_val.shape))\n",
    "\n",
    "    # Creating DMatrix(es)\n",
    "    dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "    dval = xgboost.DMatrix(X_val, label=y_val)\n",
    "    watchlist = [(dtrain, \"train\"), (dval, \"validation\")]\n",
    "\n",
    "    print('')\n",
    "    print (f'===Starting training with max_depth {max_depth}===')\n",
    "\n",
    "    param_dist = {\n",
    "        \"max_depth\": max_depth,\n",
    "        \"eta\": eta,\n",
    "        \"gamma\": gamma,\n",
    "        \"min_child_weight\": min_child_weight,\n",
    "        \"verbosity\": verbosity,\n",
    "        \"objective\": objective,\n",
    "        \"eval_metric\": eval_metric\n",
    "    }\n",
    "\n",
    "    xgb = xgboost.train(\n",
    "        params=param_dist,\n",
    "        dtrain=dtrain,\n",
    "        evals=watchlist,\n",
    "        num_boost_round=num_boost_round)\n",
    "\n",
    "    predictions = xgb.predict(dval)\n",
    "\n",
    "    print (\"Metrics for validation set\")\n",
    "    print('')\n",
    "    print (pd.crosstab(index=y_val, columns=np.round(predictions),\n",
    "                       rownames=['Actuals'], colnames=['Predictions'], margins=True))\n",
    "    print('')\n",
    "\n",
    "    rounded_predict = np.round(predictions)\n",
    "\n",
    "    val_accuracy = accuracy_score(y_val, rounded_predict)\n",
    "    val_precision = precision_score(y_val, rounded_predict)\n",
    "    val_recall = recall_score(y_val, rounded_predict)\n",
    "\n",
    "    print(\"Accuracy Model A: %.2f%%\" % (val_accuracy * 100.0))\n",
    "    print(\"Precision Model A: %.2f\" % (val_precision))\n",
    "    print(\"Recall Model A: %.2f\" % (val_recall))\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    val_auc = roc_auc_score(y_val, predictions)\n",
    "    print(\"Validation AUC A: %.2f\" % (val_auc))\n",
    "\n",
    "    model_file_path=\"/opt/ml/model/xgboost_model.bin\"\n",
    "    os.makedirs(os.path.dirname(model_file_path), exist_ok=True)\n",
    "    xgb.save_model(model_file_path)\n",
    "\n",
    "    return xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cf2c6-c029-458a-8fda-531d56a8e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta=0.3\n",
    "max_depth=8\n",
    "\n",
    "booster = train(X_train, y_train, X_val, y_val,\n",
    "              eta=eta, \n",
    "              max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d88b07-fbbe-4b16-b17d-428ea60151e7",
   "metadata": {},
   "source": [
    "## Test case 1a: Create a new model group\n",
    "\n",
    "### Expected result: A new model group should be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111390c5-16e2-4dcd-b0d1-f82a61561cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, session\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885420f4-f6be-46a3-8216-396d7d75fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "s3_bucket_name = sagemaker_session.default_bucket()\n",
    "\n",
    "sm_client = boto3.client('sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87311e4a-7463-4e53-b220-e4ad82845cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "model_package_group_name = \"test-lab-1-data-science\" + str(round(time.time()))\n",
    "model_package_group_input_dict = {\n",
    " \"ModelPackageGroupName\" : model_package_group_name,\n",
    " \"ModelPackageGroupDescription\" : \"Sample model package group\"\n",
    "}\n",
    "\n",
    "create_model_package_group_response = sm_client.create_model_package_group(**model_package_group_input_dict)\n",
    "\n",
    "model_package_group_arn = create_model_package_group_response['ModelPackageGroupArn']\n",
    "print('ModelPackageGroup Arn : {}'.format(create_model_package_group_response['ModelPackageGroupArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a4e43-496d-4cc4-8408-89cdac92553b",
   "metadata": {},
   "source": [
    "## Test case 1b: Register a new model version\n",
    "\n",
    "### Expected result: A new model version should be registered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad603289-2e24-4798-96df-fd1c3e426eb1",
   "metadata": {},
   "source": [
    "Utility function for getting the last succeed job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9de1cd-a3a7-4a8c-8e33-d3dd1a402ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_prefix = \"amzn-sm-btd-train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbef54d-04af-4218-af9d-cd5d2edbb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_job_name(job_name_prefix):\n",
    "    import boto3\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "    search_response = sagemaker_client.search(\n",
    "        Resource='TrainingJob',\n",
    "        SearchExpression={\n",
    "            'Filters': [\n",
    "                {\n",
    "                    'Name': 'TrainingJobName',\n",
    "                    'Operator': 'Contains',\n",
    "                    'Value': job_name_prefix\n",
    "                },\n",
    "                {\n",
    "                    'Name': 'TrainingJobStatus',\n",
    "                    'Operator': 'Equals',\n",
    "                    'Value': \"Completed\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        SortBy='CreationTime',\n",
    "        SortOrder='Descending',\n",
    "        MaxResults=1)\n",
    "\n",
    "    return search_response['Results'][0]['TrainingJob']['TrainingJobName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8aa2a6-5d09-4a5f-ad1f-13f9e43c60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = get_last_job_name(job_prefix)\n",
    "\n",
    "job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13405871-64a6-4b03-8b20-f118fd3b8dce",
   "metadata": {},
   "source": [
    "Create model package specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ddb9af-4986-4677-a900-b528d282f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec76170-0958-41af-8eeb-7f8ec0e488a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = retrieve(\"xgboost\", region=region, version=\"latest\", image_scope=\"inference\")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37afb891-3b25-4a41-8feb-a5d80789db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model source\n",
    "model_url = f\"s3://{s3_bucket_name}/{job_name}/{job_name}/output/model.tar.gz\"\n",
    "\n",
    "modelpackage_inference_specification =  {\n",
    "    \"InferenceSpecification\": {\n",
    "      \"Containers\": [\n",
    "         {\n",
    "            \"Image\": image_uri,\n",
    "    \t    \"ModelDataUrl\": model_url\n",
    "         }\n",
    "      ],\n",
    "      \"SupportedContentTypes\": [ \"text/csv\" ],\n",
    "      \"SupportedResponseMIMETypes\": [ \"text/csv\" ],\n",
    "   }\n",
    " }\n",
    "\n",
    "create_model_package_input_dict = {\n",
    "    \"ModelPackageGroupName\" : model_package_group_name,\n",
    "    \"ModelPackageDescription\" : \"Model to detect 3 different types of irises (Setosa, Versicolour, and Virginica)\",\n",
    "    \"ModelApprovalStatus\" : \"PendingManualApproval\"\n",
    "}\n",
    "create_model_package_input_dict.update(modelpackage_inference_specification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddf1a2e-1e74-4fa7-a9c2-bc97e78d24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_package_response = sm_client.create_model_package(**create_model_package_input_dict)\n",
    "model_package_arn = create_model_package_response[\"ModelPackageArn\"]\n",
    "print('ModelPackage Version ARN : {}'.format(model_package_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add351d-40d0-4caf-b066-7aa561a1199d",
   "metadata": {},
   "source": [
    "## Test case 1c: Delete a model version\n",
    "\n",
    "### Expected result: Model version should be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2c149-1297-4f9c-941e-0c36a89523d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_client.delete_model_package(\n",
    "    ModelPackageName=model_package_arn\n",
    ")\n",
    "\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
