{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b43513c-5b7d-43fa-a52b-58cc0269b17d",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd38eb1-5b39-4007-a64b-1a78c50726f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9b710-34b7-4223-a42c-f39fabc8cea0",
   "metadata": {},
   "source": [
    "# Import SageMaker Defaults Configurations\n",
    "\n",
    "The Amazon SageMaker Python SDK supports setting of default values for AWS infrastructure primitive types, such as instance types, Amazon S3 folder locations, and IAM roles. You can override the default locations of these files by setting the `SAGEMAKER_USER_CONFIG_OVERRIDE` environment variables for the user-defined configuration file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532bf10-e09d-4db9-89bc-075f43127781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use the current working directory as the location for SageMaker Python SDK config file\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97fa9c2-5286-4352-91f6-ef4e8cb9336f",
   "metadata": {},
   "source": [
    "# Download dataset\n",
    "\n",
    "Download the dataset from the UCI website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a879f4d-dbc6-4059-95c9-c663d679dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "\n",
    "input_data_dir = 'data/'\n",
    "if not os.path.exists(input_data_dir):\n",
    "    os.makedirs(input_data_dir)\n",
    "input_data_path = os.path.join(input_data_dir, 'predictive_maintenance_raw_data_header.csv')\n",
    "dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv\"\n",
    "urllib.request.urlretrieve(dataset_url, input_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a696576-4402-4eb7-a0ba-fce791452037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(input_data_path)\n",
    "\n",
    "print('The shape of the dataset is:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e50a99b-2f17-4449-9719-f30d89687cfb",
   "metadata": {},
   "source": [
    "# Test case 1: Run a SageMaker Job without Networking configurations\n",
    "\n",
    "## Expected result: Job should fail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfaec1d-82d4-4261-818d-798f70e2cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sagemaker.remote_function import remote\n",
    "\n",
    "@remote(job_name_prefix=\"amzn-sm-btd-preprocess\")\n",
    "def preprocess(df):\n",
    "    columns = ['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Machine failure']\n",
    "    cat_columns = ['Type']\n",
    "    num_columns = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
    "    target_column = 'Machine failure'\n",
    "\n",
    "    df = df[columns]\n",
    "\n",
    "    training_ratio = 0.8\n",
    "    validation_ratio = 0.1\n",
    "    test_ratio = 0.1\n",
    "\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "\n",
    "    print(f'Splitting data training ({training_ratio}), validation ({validation_ratio}), and test ({test_ratio}) sets ')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_ratio/(validation_ratio+training_ratio), random_state=2, stratify=y_train)\n",
    "\n",
    "    # Apply transformations\n",
    "    transformer = ColumnTransformer(transformers=[('numeric', StandardScaler(), num_columns),\n",
    "                                                  ('categorical', OneHotEncoder(), cat_columns)],\n",
    "                                    remainder='passthrough')\n",
    "    featurizer_model = transformer.fit(X_train)\n",
    "    X_train = featurizer_model.transform(X_train)\n",
    "    X_val = featurizer_model.transform(X_val)\n",
    "\n",
    "    print(f'Shape of train features after preprocessing: {X_train.shape}')\n",
    "    print(f'Shape of validation features after preprocessing: {X_val.shape}')\n",
    "    print(f'Shape of test features after preprocessing: {X_test.shape}')\n",
    "    \n",
    "    y_train = y_train.values.reshape(-1)\n",
    "    y_val = y_val.values.reshape(-1)\n",
    "    \n",
    "    print(f'Shape of train labels after preprocessing: {y_train.shape}')\n",
    "    print(f'Shape of validation labels after preprocessing: {y_val.shape}')\n",
    "    print(f'Shape of test labels after preprocessing: {y_test.shape}')\n",
    "\n",
    "    model_file_path=\"/opt/ml/model/sklearn_model.joblib\"\n",
    "    os.makedirs(os.path.dirname(model_file_path), exist_ok=True)\n",
    "    joblib.dump(featurizer_model, model_file_path)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, featurizer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cebde5c-fffa-41af-a46c-e83263f339a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, featurizer_model = preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35d519-130f-45c9-847f-93167bfe9ba6",
   "metadata": {},
   "source": [
    "# Test case 2: Run a SageMaker Job with Networking configurations\n",
    "\n",
    "## Expected result: The job should be successfully executed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d02b8-652e-410c-a525-f1e5963a5893",
   "metadata": {},
   "source": [
    "## Subnet and security group definition\n",
    "\n",
    "#### ! Important: Populate subnets and security_group_ids by using the exported values from the CloudFormation template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26abc68f-ddd7-4392-8127-94a97e271e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnets = []\n",
    "security_group_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7f1e7-5073-4979-92b3-ec81e3bf2cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sagemaker.remote_function import remote\n",
    "\n",
    "@remote(job_name_prefix=\"amzn-sm-btd-preprocess\", subnets=subnets, security_group_ids=security_group_ids)\n",
    "def preprocess(df):\n",
    "    columns = ['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Machine failure']\n",
    "    cat_columns = ['Type']\n",
    "    num_columns = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
    "    target_column = 'Machine failure'\n",
    "\n",
    "    df = df[columns]\n",
    "\n",
    "    training_ratio = 0.8\n",
    "    validation_ratio = 0.1\n",
    "    test_ratio = 0.1\n",
    "\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "\n",
    "    print(f'Splitting data training ({training_ratio}), validation ({validation_ratio}), and test ({test_ratio}) sets ')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_ratio/(validation_ratio+training_ratio), random_state=2, stratify=y_train)\n",
    "\n",
    "    # Apply transformations\n",
    "    transformer = ColumnTransformer(transformers=[('numeric', StandardScaler(), num_columns),\n",
    "                                                  ('categorical', OneHotEncoder(), cat_columns)],\n",
    "                                    remainder='passthrough')\n",
    "    featurizer_model = transformer.fit(X_train)\n",
    "    X_train = featurizer_model.transform(X_train)\n",
    "    X_val = featurizer_model.transform(X_val)\n",
    "\n",
    "    print(f'Shape of train features after preprocessing: {X_train.shape}')\n",
    "    print(f'Shape of validation features after preprocessing: {X_val.shape}')\n",
    "    print(f'Shape of test features after preprocessing: {X_test.shape}')\n",
    "    \n",
    "    y_train = y_train.values.reshape(-1)\n",
    "    y_val = y_val.values.reshape(-1)\n",
    "    \n",
    "    print(f'Shape of train labels after preprocessing: {y_train.shape}')\n",
    "    print(f'Shape of validation labels after preprocessing: {y_val.shape}')\n",
    "    print(f'Shape of test labels after preprocessing: {y_test.shape}')\n",
    "\n",
    "    model_file_path=\"/opt/ml/model/sklearn_model.joblib\"\n",
    "    os.makedirs(os.path.dirname(model_file_path), exist_ok=True)\n",
    "    joblib.dump(featurizer_model, model_file_path)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, featurizer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73afdca9-1f4a-462c-bb65-47baa141d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, featurizer_model = preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3577869-e29d-4b19-b971-c15b32504ee8",
   "metadata": {},
   "source": [
    "# Test case 3: Register features in feature store\n",
    "\n",
    "## Expected result: Features should be registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d2de0-c386-4549-8c9d-b0173e4238f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "prefix = \"sagemaker-featurestore-introduction\"\n",
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "s3_bucket_name = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e336f9-5dc3-4dd7-9e84-96d457dcae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec05d45-7159-414f-938c-2ec186e4b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Machine failure']\n",
    "\n",
    "new_columns = [col.replace('[', '').replace(']', '').replace(' ', '_') for col in df.columns]\n",
    "df_copy.columns = new_columns\n",
    "\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b1218-1763-4679-9d42-923a7b33cae0",
   "metadata": {},
   "source": [
    "## Test case 3a: Create a Feature Group\n",
    "\n",
    "### Expected result: A new feature group should be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f376d-c40c-4172-b37c-1e35c68b548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "product_id_feature_group_name = \"product-id-feature-group-\" + strftime(\"%d-%H-%M-%S\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42316905-ab1e-4a1b-ab2e-44e01c9ca9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "product_id_feature_group = FeatureGroup(\n",
    "    name=product_id_feature_group_name, sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b9d85-68a5-46fb-987c-cc9228757232",
   "metadata": {},
   "source": [
    "## Test case 3b: Create a Feature Group definition\n",
    "\n",
    "### Expected result: A new feature group definition from the dataset should be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8b6cf-aab6-49b0-be54-863e1f7ea7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "current_time_sec = int(round(time.time()))\n",
    "\n",
    "record_identifier_feature_name = \"Product_ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed7437-006c-43f4-b486-a8863567a432",
   "metadata": {},
   "source": [
    "Append `EventTime` feature to your data frame. This parameter is required, and time stamps each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d571b4-66e5-4a5e-89bb-c45858570ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[\"EventTime\"] = pd.Series([current_time_sec] * len(df_copy), dtype=\"float64\")\n",
    "\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3982de2-72c5-4552-8f57-65943476786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id_feature_group.load_feature_definitions(data_frame=df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aefb90-6256-44f2-a6a4-903c2af7c95b",
   "metadata": {},
   "source": [
    "Below we call create to create the feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600470f6-f8df-4121-8314-0678f99e321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id_feature_group.create(\n",
    "    s3_uri=f\"s3://{s3_bucket_name}/{prefix}\",\n",
    "    record_identifier_name=record_identifier_feature_name,\n",
    "    event_time_feature_name=\"EventTime\",\n",
    "    role_arn=role,\n",
    "    enable_online_store=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c73b813-95f4-4d4c-a701-2eb23523d901",
   "metadata": {},
   "source": [
    "# Test case 4: Register model in model registry\n",
    "\n",
    "## Expected result: A new model version should be registered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686bcda-a6a2-46ef-9496-2e905d99b6d4",
   "metadata": {},
   "source": [
    "#### ! Important: Populate subnets and security_group_ids by using the exported values from the CloudFormation template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb140719-c21d-42f4-a7d0-9a2cb4501593",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnets = []\n",
    "security_group_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40532a1f-68ee-4d0e-a46e-919249aebc6b",
   "metadata": {},
   "source": [
    "Run data processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24cd97e-6cbb-4bd3-8cdc-84cc2e50e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sagemaker.remote_function import remote\n",
    "\n",
    "@remote(job_name_prefix=\"amzn-sm-btd-preprocess\", subnets=subnets, security_group_ids=security_group_ids)\n",
    "def preprocess(df):\n",
    "    columns = ['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Machine failure']\n",
    "    cat_columns = ['Type']\n",
    "    num_columns = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
    "    target_column = 'Machine failure'\n",
    "\n",
    "    df = df[columns]\n",
    "\n",
    "    training_ratio = 0.8\n",
    "    validation_ratio = 0.1\n",
    "    test_ratio = 0.1\n",
    "\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "\n",
    "    print(f'Splitting data training ({training_ratio}), validation ({validation_ratio}), and test ({test_ratio}) sets ')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_ratio/(validation_ratio+training_ratio), random_state=2, stratify=y_train)\n",
    "\n",
    "    # Apply transformations\n",
    "    transformer = ColumnTransformer(transformers=[('numeric', StandardScaler(), num_columns),\n",
    "                                                  ('categorical', OneHotEncoder(), cat_columns)],\n",
    "                                    remainder='passthrough')\n",
    "    featurizer_model = transformer.fit(X_train)\n",
    "    X_train = featurizer_model.transform(X_train)\n",
    "    X_val = featurizer_model.transform(X_val)\n",
    "\n",
    "    print(f'Shape of train features after preprocessing: {X_train.shape}')\n",
    "    print(f'Shape of validation features after preprocessing: {X_val.shape}')\n",
    "    print(f'Shape of test features after preprocessing: {X_test.shape}')\n",
    "    \n",
    "    y_train = y_train.values.reshape(-1)\n",
    "    y_val = y_val.values.reshape(-1)\n",
    "    \n",
    "    print(f'Shape of train labels after preprocessing: {y_train.shape}')\n",
    "    print(f'Shape of validation labels after preprocessing: {y_val.shape}')\n",
    "    print(f'Shape of test labels after preprocessing: {y_test.shape}')\n",
    "\n",
    "    model_file_path=\"/opt/ml/model/sklearn_model.joblib\"\n",
    "    os.makedirs(os.path.dirname(model_file_path), exist_ok=True)\n",
    "    joblib.dump(featurizer_model, model_file_path)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, featurizer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dcc456-4258-44bb-ad10-1d0fa7c82e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, featurizer_model = preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ee840-97c1-44f5-bb86-ea506ebf0eef",
   "metadata": {},
   "source": [
    "Run training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c840c814-69e9-40ed-93b7-c3c44c33bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xgboost\n",
    "import numpy as np\n",
    "\n",
    "from sagemaker.remote_function import remote\n",
    "\n",
    "@remote(job_name_prefix=\"amzn-sm-btd-train\", subnets=subnets, security_group_ids=security_group_ids)\n",
    "def train(X_train, y_train, X_val, y_val,\n",
    "          eta=0.1, \n",
    "          max_depth=2, \n",
    "          gamma=0.0,\n",
    "          min_child_weight=1,\n",
    "          verbosity=0,\n",
    "          objective='binary:logistic',\n",
    "          eval_metric='auc',\n",
    "          num_boost_round=5):\n",
    "\n",
    "    print('Train features shape: {}'.format(X_train.shape))\n",
    "    print('Train labels shape: {}'.format(y_train.shape))\n",
    "    print('Validation features shape: {}'.format(X_val.shape))\n",
    "    print('Validation labels shape: {}'.format(y_val.shape))\n",
    "\n",
    "    # Creating DMatrix(es)\n",
    "    dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "    dval = xgboost.DMatrix(X_val, label=y_val)\n",
    "    watchlist = [(dtrain, \"train\"), (dval, \"validation\")]\n",
    "\n",
    "    print('')\n",
    "    print (f'===Starting training with max_depth {max_depth}===')\n",
    "\n",
    "    param_dist = {\n",
    "        \"max_depth\": max_depth,\n",
    "        \"eta\": eta,\n",
    "        \"gamma\": gamma,\n",
    "        \"min_child_weight\": min_child_weight,\n",
    "        \"verbosity\": verbosity,\n",
    "        \"objective\": objective,\n",
    "        \"eval_metric\": eval_metric\n",
    "    }\n",
    "\n",
    "    xgb = xgboost.train(\n",
    "        params=param_dist,\n",
    "        dtrain=dtrain,\n",
    "        evals=watchlist,\n",
    "        num_boost_round=num_boost_round)\n",
    "\n",
    "    predictions = xgb.predict(dval)\n",
    "\n",
    "    print (\"Metrics for validation set\")\n",
    "    print('')\n",
    "    print (pd.crosstab(index=y_val, columns=np.round(predictions),\n",
    "                       rownames=['Actuals'], colnames=['Predictions'], margins=True))\n",
    "    print('')\n",
    "\n",
    "    rounded_predict = np.round(predictions)\n",
    "\n",
    "    val_accuracy = accuracy_score(y_val, rounded_predict)\n",
    "    val_precision = precision_score(y_val, rounded_predict)\n",
    "    val_recall = recall_score(y_val, rounded_predict)\n",
    "\n",
    "    print(\"Accuracy Model A: %.2f%%\" % (val_accuracy * 100.0))\n",
    "    print(\"Precision Model A: %.2f\" % (val_precision))\n",
    "    print(\"Recall Model A: %.2f\" % (val_recall))\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    val_auc = roc_auc_score(y_val, predictions)\n",
    "    print(\"Validation AUC A: %.2f\" % (val_auc))\n",
    "\n",
    "    model_file_path=\"/opt/ml/model/xgboost_model.bin\"\n",
    "    os.makedirs(os.path.dirname(model_file_path), exist_ok=True)\n",
    "    xgb.save_model(model_file_path)\n",
    "\n",
    "    return xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cf2c6-c029-458a-8fda-531d56a8e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta=0.3\n",
    "max_depth=8\n",
    "\n",
    "booster = train(X_train, y_train, X_val, y_val,\n",
    "              eta=eta, \n",
    "              max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d88b07-fbbe-4b16-b17d-428ea60151e7",
   "metadata": {},
   "source": [
    "## Test case 4a: Create a new model group\n",
    "\n",
    "### Expected result: A new model group should be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111390c5-16e2-4dcd-b0d1-f82a61561cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, session\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885420f4-f6be-46a3-8216-396d7d75fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "s3_bucket_name = sagemaker_session.default_bucket()\n",
    "\n",
    "sm_client = boto3.client('sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87311e4a-7463-4e53-b220-e4ad82845cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "model_package_group_name = \"test-lab-1-data-science\" + str(round(time.time()))\n",
    "model_package_group_input_dict = {\n",
    " \"ModelPackageGroupName\" : model_package_group_name,\n",
    " \"ModelPackageGroupDescription\" : \"Sample model package group\"\n",
    "}\n",
    "\n",
    "create_model_package_group_response = sm_client.create_model_package_group(**model_package_group_input_dict)\n",
    "\n",
    "model_package_group_arn = create_model_package_group_response['ModelPackageGroupArn']\n",
    "print('ModelPackageGroup Arn : {}'.format(create_model_package_group_response['ModelPackageGroupArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a4e43-496d-4cc4-8408-89cdac92553b",
   "metadata": {},
   "source": [
    "## Test case 4b: Register a new model version\n",
    "\n",
    "### Expected result: A new model version should be registered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad603289-2e24-4798-96df-fd1c3e426eb1",
   "metadata": {},
   "source": [
    "Utility function for getting the last succeed job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9de1cd-a3a7-4a8c-8e33-d3dd1a402ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_prefix = \"amzn-sm-btd-train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbef54d-04af-4218-af9d-cd5d2edbb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_job_name(job_name_prefix):\n",
    "    import boto3\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "    search_response = sagemaker_client.search(\n",
    "        Resource='TrainingJob',\n",
    "        SearchExpression={\n",
    "            'Filters': [\n",
    "                {\n",
    "                    'Name': 'TrainingJobName',\n",
    "                    'Operator': 'Contains',\n",
    "                    'Value': job_name_prefix\n",
    "                },\n",
    "                {\n",
    "                    'Name': 'TrainingJobStatus',\n",
    "                    'Operator': 'Equals',\n",
    "                    'Value': \"Completed\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        SortBy='CreationTime',\n",
    "        SortOrder='Descending',\n",
    "        MaxResults=1)\n",
    "\n",
    "    return search_response['Results'][0]['TrainingJob']['TrainingJobName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8aa2a6-5d09-4a5f-ad1f-13f9e43c60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = get_last_job_name(job_prefix)\n",
    "\n",
    "job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13405871-64a6-4b03-8b20-f118fd3b8dce",
   "metadata": {},
   "source": [
    "Create model package specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ddb9af-4986-4677-a900-b528d282f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec76170-0958-41af-8eeb-7f8ec0e488a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = retrieve(\"xgboost\", region=region, version=\"latest\", image_scope=\"inference\")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37afb891-3b25-4a41-8feb-a5d80789db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model source\n",
    "model_url = f\"s3://{s3_bucket_name}/{job_name}/{job_name}/output/model.tar.gz\"\n",
    "\n",
    "modelpackage_inference_specification =  {\n",
    "    \"InferenceSpecification\": {\n",
    "      \"Containers\": [\n",
    "         {\n",
    "            \"Image\": image_uri,\n",
    "    \t    \"ModelDataUrl\": model_url\n",
    "         }\n",
    "      ],\n",
    "      \"SupportedContentTypes\": [ \"text/csv\" ],\n",
    "      \"SupportedResponseMIMETypes\": [ \"text/csv\" ],\n",
    "   }\n",
    " }\n",
    "\n",
    "create_model_package_input_dict = {\n",
    "    \"ModelPackageGroupName\" : model_package_group_name,\n",
    "    \"ModelPackageDescription\" : \"Model to detect 3 different types of irises (Setosa, Versicolour, and Virginica)\",\n",
    "    \"ModelApprovalStatus\" : \"PendingManualApproval\"\n",
    "}\n",
    "create_model_package_input_dict.update(modelpackage_inference_specification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddf1a2e-1e74-4fa7-a9c2-bc97e78d24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_package_response = sm_client.create_model_package(**create_model_package_input_dict)\n",
    "model_package_arn = create_model_package_response[\"ModelPackageArn\"]\n",
    "print('ModelPackage Version ARN : {}'.format(model_package_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add351d-40d0-4caf-b066-7aa561a1199d",
   "metadata": {},
   "source": [
    "## Test case 4c: Delete a model version\n",
    "\n",
    "### Expected result: Model version should be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2c149-1297-4f9c-941e-0c36a89523d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_client.delete_model_package(\n",
    "    ModelPackageName=model_package_arn\n",
    ")\n",
    "\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
